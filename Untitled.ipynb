{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb6485e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 9 candidates, totalling 9 fits\n",
      "[CV 1/1] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.359 total time=   2.2s\n",
      "[CV 1/1] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=0.236 total time=   0.8s\n",
      "[CV 1/1] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.361 total time=   6.0s\n",
      "[CV 1/1] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.372 total time=  12.4s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from data_loader import load_bilibili_data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def fit_linear_regression(Xmat_train, Y_train, Xmat_val, Y_val):\n",
    "    # ==================================\n",
    "    # BASELINE MODEL: LINEAR REGRESSION\n",
    "    # ==================================\n",
    "    baseline_model = LinearRegression()\n",
    "    baseline_model.fit(Xmat_train, Y_train)\n",
    "\n",
    "    # Obtain the coefficient of determination by calling the model with the score() function, then print the coefficient:\n",
    "    r_squared_train = baseline_model.score(Xmat_train, Y_train)\n",
    "    print('R-sqaured on training set:', r_squared_train)\n",
    "\n",
    "    r_squared_val = baseline_model.score(Xmat_val, Y_val)\n",
    "    print('R-sqaured on validation set:', r_squared_val)\n",
    "\n",
    "\n",
    "def fit_polynomial_regression(Xmat_train_and_val, Y_train_and_val, split_index):\n",
    "    # =====================\n",
    "    # POLYNOMIAL REGRESSION\n",
    "    # =====================\n",
    "    steps = [\n",
    "        ('poly', PolynomialFeatures()),\n",
    "        ('model', Ridge()) #Lasso(alpha=0.9, max_iter=10000, fit_intercept=True))\n",
    "    ]\n",
    "\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # =================== 1st Grid Search ===================\n",
    "    degrees = [2, 3]\n",
    "    alphas = [0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000]\n",
    "\n",
    "    param_grid = {\n",
    "        \"poly__degree\" : degrees,\n",
    "        \"model__alpha\" : alphas,\n",
    "    }\n",
    "\n",
    "    # Use the list split_index to create PredefinedSplit\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "\n",
    "    search = GridSearchCV(estimator=pipeline,\n",
    "                          param_grid=param_grid,\n",
    "                          scoring=\"r2\",\n",
    "                          cv=pds,\n",
    "                          verbose=3)\n",
    "\n",
    "    search.fit(Xmat_train_and_val, Y_train_and_val)\n",
    "\n",
    "    df_gridsearch = pd.DataFrame(search.cv_results_)\n",
    "\n",
    "    scores = search.cv_results_['split0_test_score']\n",
    "\n",
    "    # replace negatives scores with zero, then transform into the desired shape\n",
    "    scores[scores < 0] = 0\n",
    "    scores = np.array(scores)\n",
    "    scores = np.transpose(np.vstack(np.split(scores, len(alphas))))\n",
    "\n",
    "    # Plot using Matplotlib\n",
    "    for i, degree in enumerate(degrees):\n",
    "        plt.plot(np.log(alphas), scores[i], label='degree: ' + str(degree))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('log (Alpha)')\n",
    "    plt.ylabel('R Sqaured')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # =================== 2nd Grid Search ===================\n",
    "    degrees = [2]\n",
    "    alphas = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "\n",
    "    param_grid = {\n",
    "        \"poly__degree\" : degrees,\n",
    "        \"model__alpha\" : alphas,\n",
    "    }\n",
    "\n",
    "    # Use the list split_index to create PredefinedSplit\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "\n",
    "    search = GridSearchCV(estimator=pipeline,\n",
    "                          param_grid=param_grid,\n",
    "                          scoring=\"r2\",\n",
    "                          cv=pds,\n",
    "                          verbose=3)\n",
    "\n",
    "    search.fit(Xmat_train_and_val, Y_train_and_val)\n",
    "\n",
    "    df_gridsearch = pd.DataFrame(search.cv_results_)\n",
    "\n",
    "    scores = search.cv_results_['split0_test_score']\n",
    "\n",
    "    # replace negatives scores with zero, then transform into the desired shape\n",
    "    scores[scores < 0] = 0\n",
    "    scores = np.array(scores)\n",
    "    scores = np.transpose(np.vstack(np.split(scores, len(alphas))))\n",
    "\n",
    "    # Plot using Matplotlib\n",
    "    for i, degree in enumerate(degrees):\n",
    "        plt.plot(alphas, scores[i], label='degree: ' + str(degree))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('Alpha')\n",
    "    plt.ylabel('R Sqaured')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def fit_random_forest(Xmat_train_and_val, Y_train_and_val, split_index):\n",
    "    # =========================\n",
    "    # ðŸŒ²ðŸŒ²ðŸŒ² RANDOM FOREST ðŸŒ²ðŸŒ²ðŸŒ²\n",
    "    # =========================\n",
    "\n",
    "    # [CV 1/1] END bootstrap=True, max_depth=None, max_features=1.0, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=0.582 total time=   1.6s\n",
    "\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [10, 100, 500] # [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['sqrt']\n",
    "\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [10, 100] # [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2]\n",
    "\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1]\n",
    "\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True] #[True, False]\n",
    "\n",
    "    # Create the random grid\n",
    "    param_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    # Use the list split_index to create PredefinedSplit (predefined Validation set)\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "\n",
    "\n",
    "    search = GridSearchCV(estimator=rf,\n",
    "                          param_grid=param_grid,\n",
    "                          scoring=\"r2\",\n",
    "                          cv=pds,\n",
    "                          verbose=3,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "    search.fit(Xmat_train_and_val, Y_train_and_val)\n",
    "    \n",
    "    return search.cv_results_\n",
    "\n",
    "#     df_gridsearch = pd.DataFrame(search.cv_results_)\n",
    "\n",
    "#     scores = search.cv_results_['split0_test_score']\n",
    "\n",
    "    # Random search of parameters, using predefined validation set,\n",
    "    # search across 100 different combinations, and use all available cores.\n",
    "    # P.S. n_jobs = -1 means use all processors to run them in parallel\n",
    "    # rf_random = RandomizedSearchCV(estimator=rf,\n",
    "    #                                param_distributions=param_grid,\n",
    "    #                                scoring=\"r2\",\n",
    "    #                                n_iter=100,\n",
    "    #                                cv=pds,\n",
    "    #                                verbose=3,\n",
    "    #                                random_state=2022,\n",
    "    #                                n_jobs=-1)\n",
    "    #\n",
    "    # rf_random.fit(Xmat_train_and_val, Y_train_and_val)\n",
    "\n",
    "def main():\n",
    "\n",
    "    # All of those are pandas objects\n",
    "    Xmat_train_and_val, Y_train_and_val, Xmat_train, Xmat_val, Xmat_test, Y_train, Y_val, Y_test = load_bilibili_data()\n",
    "\n",
    "    # Create a list where train data indices are -1 and validation data indices are 0\n",
    "    split_index = [-1 if x in Xmat_train.index else 0 for x in Xmat_train_and_val.index]\n",
    "\n",
    "    # fit_linear_regression(Xmat_train, Y_train, Xmat_val, Y_val)\n",
    "    #\n",
    "    # fit_polynomial_regression(Xmat_train_and_val, Y_train_and_val, split_index)\n",
    "\n",
    "    result = fit_random_forest(Xmat_train_and_val, Y_train_and_val, split_index)\n",
    "\n",
    "    #\n",
    "    # for i in range(29, 40):\n",
    "    #     print(\"max_features = \", i)\n",
    "    #     forest = RandomForestRegressor(n_estimators=100, max_features=i)\n",
    "    #     forest.fit(Xmat_train, Y_train)\n",
    "    #     print('Training score: {}'.format(forest.score(Xmat_train, Y_train)))\n",
    "    #     print('Validation score: {}'.format(forest.score(Xmat_val, Y_val)))\n",
    "    #     print(\"\\n\")\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cd0095b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresult\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1dd365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
